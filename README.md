# Emotion Prediction from Facial Expressions with VGG19

This project builds a **multi-class image classification model** using a **VGG19** convolutional backbone to automatically predict human emotions from facial images. We train and evaluate on the **FER2013** dataset.

## ğŸ“Š Dataset Overview

The **FER2013** dataset contains **48Ã—48** grayscale (converted to RGB) face images labeled with one of seven emotions:

| Label       | Emotion       |
| ----------- | ------------- |
| 0           | Anger         |
| 1           | Disgust       |
| 2           | Fear          |
| 3           | Happy         |
| 4           | Sad           |
| 5           | Surprise      |
| 6           | Neutral       |

- **Total images:** ~35,000  
- **Train/Validation/Test split:** 80% / 10% / 10%

## ğŸ§¹ Data Preprocessing

1. **Image resizing** to 48Ã—48 pixels, converted from grayscale â†’ RGB  
2. **Normalization**: pixel values scaled to [0, 1]  
3. **Label encoding** into one-hot vectors  
4. **Augmentation** via `ImageDataGenerator`:
   - Rotation (Â±15Â°)
   - Width/height shifts (Â±15%)
   - Horizontal flips  

## ğŸ“ˆ Exploratory Data Analysis

- **Class distribution** bar plot shows slight imbalance (Happy & Neutral most frequent).  
- **Sample grid** displays random faces per emotion.  

## ğŸ§  Model Building

- **Backbone:** `tf.keras.applications.VGG19`  
  - `include_top=False`, input shape=(48, 48, 3)  
  - Loaded pretrained â€œno-topâ€ weights  
- **Head:**
  - `Flatten()`
  - `Dense(256, activation='relu')`
  - `Dropout(0.5)`
  - `Dense(7, activation='softmax')`
- **Compile:**  
  ```python
  model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
  )

**Callbacks:** EarlyStopping on `val_accuracy` (patience=10)

## ğŸ§ª Training & Evaluation

* **Batch size:** 32
* **Epochs:** up to 50
* **Results:**

  * **Train accuracy:** \~75%
  * **Validation accuracy:** \~70%
* **Visualization:**

  * Training vs. validation **accuracy** and **loss** curves
  * **Confusion matrix** heatmap

## âš™ï¸ Installation

1. **Clone** this repository:

   ```bash
   git clone https://github.com/NishatTasnim01/Emotion-Prediction-Facial-Expressions.git
   cd Emotion-Prediction-Facial-Expressions
   ```
2. **Install** dependencies:

   ```bash
   pip install -r requirements.txt
   ```
3. **Launch** the notebook:

   ```bash
   jupyter notebook emotion-prediction-from-facial-expressions-final.ipynb
   ```

## ğŸ“ Project Structure

```
â”œâ”€â”€ emotion-prediction-from-facial-expressions-final.ipynb
â”œâ”€â”€ models/
â”‚   â””â”€â”€ vgg19_emotion_weights.h5
â”œâ”€â”€ data/
â”‚   â””â”€â”€ fer2013.csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ‘©â€ğŸ’» Developed By

ğŸ”— [Nishat Tasnim](https://github.com/NishatTasnim01)

## ğŸ™Œ Acknowledgment

[FER2013 Dataset](https://datasets.activeloop.ai/docs/ml/datasets/fer2013-dataset/)


â­ *If you found this project helpful, please give it a star!*
